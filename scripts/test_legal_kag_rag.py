#!/usr/bin/env python3
"""
Test KAG-RAG integration with the legal document generated by single orchestration.
"""

import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from services.rag_adapter import load_and_normalize, create_chunks_for_embeddings

def test_legal_document_kag_rag():
    """Test KAG-RAG integration with the legal document."""
    
    # Test with the newly generated KAG input
    test_file = 'artifacts/single_test/test-1758420383/kag_input.json'
    
    print('ğŸ§ª Testing KAG-RAG integration with legal document:')
    print('ğŸ“„ File: 077-NLR-NLR-V-72-T.-P.-VEERAPPEN-Appellant-and-THE-ATTORNEY-GENERAL-Respondent.pdf')
    print(f'ğŸ“„ KAG input: {test_file}')
    print()
    
    try:
        # Load and test with RAG adapter
        docs = load_and_normalize(test_file)
        print(f'âœ… Loaded {len(docs)} documents via RAG adapter')
        
        if not docs:
            print('âŒ No documents loaded')
            return False
        
        doc = docs[0]
        print(f'ğŸ“‹ Document ID: {doc["document_id"]}')
        print(f'ğŸ·ï¸  Classification: {doc["classifier"]["label"]} (confidence: {doc["document_confidence"]:.3f})')
        print(f'ğŸ“„ Text length: {len(doc["full_text"])} characters')
        print(f'ğŸ“¦ Total chunks: {len(doc["chunks"])}')
        
        # Create embedding-ready chunks
        embedding_chunks = create_chunks_for_embeddings(doc)
        print(f'ğŸ¯ Embedding-ready chunks: {len(embedding_chunks)}')
        
        # Simulate RAG conversion
        rag_chunks = []
        for chunk in embedding_chunks:
            rag_chunks.append({
                "text": chunk["text"],
                "chunk_id": chunk["chunk_id"],
                "document_id": chunk["metadata"]["document_id"],
                "classifier_label": chunk["metadata"]["classifier_label"],
                "document_confidence": chunk["metadata"]["document_confidence"],
                "chunk_type": chunk["metadata"]["chunk_type"],
                "source_format": chunk["metadata"]["source_format"]
            })
        
        print(f'ğŸ”„ Converted to RAG format: {len(rag_chunks)} chunks')
        
        # Test enhanced QA prompt
        sample_chunks = rag_chunks[:3]
        print(f'\nğŸ“ Enhanced QA prompt sample for legal document:')
        for i, chunk in enumerate(sample_chunks, start=1):
            classifier = chunk["classifier_label"]
            confidence = chunk["document_confidence"]
            text_preview = chunk["text"][:100] + "..." if len(chunk["text"]) > 100 else chunk["text"]
            print(f'   Context {i} [{classifier}] (confidence: {confidence:.2f}): {text_preview} (doc:{chunk["chunk_id"]})')
        
        print(f'\nğŸ‰ Legal document successfully processed through KAG-RAG pipeline!')
        print(f'ğŸ“Š Ready for legal Q&A and risk analysis with enhanced context!')
        return True
        
    except Exception as e:
        print(f'âŒ Test failed: {e}')
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    if test_legal_document_kag_rag():
        print('\nğŸ† Legal document KAG-RAG integration successful!')
        sys.exit(0)
    else:
        print('\nâŒ Integration test failed')
        sys.exit(1)